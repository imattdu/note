

# 状态编程和容错机制





## 举例





- 所有类型的窗口。例如，计算过去一小时的平均温度，就是有状态的计算。
- 所有用于复杂事件处理的状态机。例例如，若在一分钟内收到两个相差 20 度 以上的温度读数，则发出警告，这是有状态的计算。
- 流与流之间的所有关联操作，以及流与静态表或动态表之间的关联操作， 都是有状态的计算。







下图展示了无状态流处理和有状态流处理的主要区别。无状态流处理分别接收 每条数据记录(图中的黑条)，然后根据最新输入的数据生成输出数据(白条)。有状态 流处理会维护状态(根据每条输入记录进行更新)，并基于最新输入的记录和当前的状态值生成输出记录(灰条)。





![](https://raw.githubusercontent.com/imattdu/img/main/img/202203160117378.png)









## 有状态的算子和应用程序



Flink 内置的很多算子，数据源 source，数据存储 sink 都是有状态的，流中的数 据都是 buffer records，会保存一定的元素或者元数据。例如: ProcessWindowFunction 会缓存输入流的数据，ProcessFunction 会保存设置的定时器信息等等。 在 Flink 中，状态始终与特定算子相关联。

总的来说，有两种类型的状态： ⚫ 算子状态（operator state） ⚫ 键控状态（keyed state）









### 算子状态





算子状态的作用范围限定为算子任务。这意味着由同一并行任务所处理的所有 数据都可以访问到相同的状态，状态对于同一任务而言是共享的。算子状态不能由 相同或不同算子的另一个任务访问。





![](https://raw.githubusercontent.com/imattdu/img/main/img/202203160122787.png)





Flink 为算子状态提供三种基本数据结构： 

- 列表状态（List state） 将状态表示为一组数据的列表。 
- 联合列表状态（Union list state） 也将状态表示为数据的列表。它与常规列表状态的区别在于，在发生故障时，或者从保存点（savepoint）启动应用程序时如何恢复。
- 广播状态（Broadcast state） 如果一个算子有多项任务，而它的每项任务状态又都相同，那么这种特殊情况最适合应 用广播状态。





### 键控状态





具有相同 key 的所有数据都会访问相同的状态。

Keyed State 很类似于 一个分布式的 key-value map 数据结构，只能用于 KeyedStream（keyBy 算子处理之后）。





![](https://raw.githubusercontent.com/imattdu/img/main/img/202203191745077.png)







Flink 的 Keyed State 支持以下数据类型



ValueState保存单个的值，值的类型为 T。

- get 操作: ValueState.value()
- set 操作: ValueState.update(T value)



ListState保存一个列表，列表里的元素的数据类型为 T。基本操作如下：

- ListState.add(T value)

- ListState.addAll(List values)

- ListState.get()返回 Iterable

- ListState.update(List values)



MapState保存 Key-Value 对

- MapState.get(UK key)
- MapState.put(UK key, UV value)
- MapState.contains(UK key)
- MapState.remove(UK key)



ReducingState<T>

AggregatingState<I, O>



**State.clear()是清空操作。**





```java
package com.matt.apitest.state;

import com.matt.apitest.beans.SensorReading;
import org.apache.commons.digester.SetNestedPropertiesRule;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.api.common.functions.RichMapFunction;
import org.apache.flink.api.common.state.*;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.checkpoint.ListCheckpointed;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.hadoop.util.hash.Hash;
import sun.management.Sensor;

import java.util.Collections;
import java.util.HashMap;
import java.util.List;

public class StateTest2_KeyedState {


    public static void main(String[] args) throws Exception {


        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        DataStream<String> inputStream = env.socketTextStream("localhost", 777);
        // 转换成SensorReading类型
        DataStream<SensorReading> dataStream = inputStream.map(line -> {
            String[] fields = line.split(",");
            return new SensorReading(fields[0], new Long(fields[1]), new Double(fields[2]));
        });

        SingleOutputStreamOperator<Integer> res = dataStream.keyBy("id").map(new MyKeyCountMapper());

        res.print();

        env.execute("my");

    }


    public static class MyKeyCountMapper extends RichMapFunction<SensorReading, Integer>{

        private ValueState<Integer> keyCountState;

        private ListState<String> listState;
        private MapState<String, String> mapState;

        private ReducingState<SensorReading> readingReducingState;

        @Override
        public void open(Configuration parameters) throws Exception {
            keyCountState = getRuntimeContext().getState(
                    new ValueStateDescriptor<Integer>("keyedCount", Integer.class,0)
            );

            // name:不能相同
            listState = getRuntimeContext().getListState(
                    new ListStateDescriptor<String>("listState", String.class)
            );

            mapState = getRuntimeContext().getMapState(
              new MapStateDescriptor<String, String>("mapState", String.class, String.class)
            );

            //readingReducingState = getRuntimeContext().getReducingState(
            //    new ReducingStateDescriptor<SensorReading>("reducingState", new )
            //);
        }

        @Override
        public Integer map(SensorReading sensorReading) throws Exception {
            Integer count = keyCountState.value();
            count++;
            keyCountState.update(count);

            Iterable<String> strings = listState.get();

            for (String string : strings) {
                System.out.println(string) ;
            }

            listState.add("hello");

            // mapState
            // readingReducingState add 方法直接聚合


            return count;
        }
    }

}

```







### 案例





检测传感器的温度值，如果连 续的两个温度差值超过 10 度，就输出报警。



```java
package com.matt.apitest.state;

import com.matt.apitest.beans.SensorReading;
import org.apache.flink.api.common.functions.RichFlatMapFunction;
import org.apache.flink.api.common.state.*;
import org.apache.flink.api.java.tuple.Tuple3;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.util.Collector;

public class StateTest3_keyedstate_app1 {

    public static void main(String[] args) throws Exception {


        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        DataStream<String> inputStream = env.socketTextStream("localhost", 777);
        // 转换成SensorReading类型
        DataStream<SensorReading> dataStream = inputStream.map(line -> {
            String[] fields = line.split(",");
            return new SensorReading(fields[0], new Long(fields[1]), new Double(fields[2]));
        });

        // warn
        SingleOutputStreamOperator<Tuple3<String, Double, Double>> res = dataStream.keyBy("id")
                .flatMap(new TempChangeWarning(10.0));

        res.print();

        env.execute("my");

    }


    public static class TempChangeWarning extends RichFlatMapFunction<SensorReading, Tuple3<String, Double, Double>> {

        private Double threshold = 10.0;

        // 状态 上一次温度值
        private ValueState<Double> lastTempState;

        public TempChangeWarning(Double threshold) {
            this.threshold = threshold;
        }

        @Override
        public void open(Configuration parameters) throws Exception {
            lastTempState = getRuntimeContext().getState(
                    new ValueStateDescriptor<Double>("last-temp", Double.class)
            );
        }

        @Override
        public void flatMap(SensorReading sensorReading, Collector<Tuple3<String, Double, Double>> collector) throws Exception {

            Double lastTemp = lastTempState.value();

            if (lastTemp != null && Math.abs(sensorReading.getTemperatrue() - lastTemp) > threshold) {
                collector.collect(new Tuple3<>("报警" + sensorReading.getId(), sensorReading.getTemperatrue(), lastTemp));
            }

            lastTempState.update(sensorReading.getTemperatrue());
        }

        @Override
        public void close() throws Exception {
            // 清理状态
            lastTempState.clear();
        }
    }

}

```



## 状态一致性





正确性的级别， 发生故障恢复 和没有发生故障二者的结果





### 一致性级别





- at-most-once: 这其实是没有正确性保障的委婉说法——故障发生之后，计数结果可能丢失。同样的还有 udp。 **最多一次**
- at-least-once: 这表示计数结果可能大于正确值，但绝不会小于正确值。也 就是说，计数程序在发生故障后可能多算，但是绝不会少算。 **最少一次**
- exactly-once: 这指的是系统保证在发生故障后得到的计数结果与正确值一致。 **精准一次**







### 端到端一致性





内部保证 —— 依赖 checkpoint

source 端 —— 需要外部源可重设数据的读取位置 

sink 端 —— 需要保证从故障恢复时，数据不会重复写入外部系统 





而对于 sink 端，又有两种具体的实现方式：

幂等（Idempotent）写入和事务性 （Transactional）写入。



所谓幂等操作，是说一个操作，可以重复执行很多次，但只导致一次结果更改， 也就是说，后面再重复执行就不起作用了。

需要构建事务来写入外部系统，构建的事务对应着 checkpoint，等到 checkpoint 真正完成的时候，才把所有对应的结果写入 sink 系统中。



对于事务性写入，具体又有两种实现方式：预写日志（WAL）和两阶段提交 （2PC）。DataStream API 提供了 GenericWriteAheadSink 模板类和 TwoPhaseCommitSinkFunction 接口，可以方便地实现这两种方式的事务性写入。





![](https://raw.githubusercontent.com/imattdu/img/main/img/202203191806635.png)





**TODO 预写日志**





## 检查点



### Flink 的检查点算法



现有一个算法：任务1：根据第一个元素分组， 任务2：第二个元素求和









![](https://raw.githubusercontent.com/imattdu/img/main/img/202203191936446.png)





检查点之前：b2 c1 b3

检查点之后：a2 a2 c2







当读取输入流的数据源(在本例中与 keyBy 算子内联) 遇到检查点屏障时，它将其在输入流中的位置保存到持久化存储中。如果输入流来 自消息传输系统(Kafka)，这个位置就是偏移量。Flink 的存储机制是插件化的，持久 化存储可以是分布式文件系统，如 HDFS。下图展示了这个过程。



![](https://raw.githubusercontent.com/imattdu/img/main/img/202203191939669.png)







检查点像普通数据记录一样在算子之间流动。当 map 算子处理完前 3 条数据并 收到检查点分界线时，它们会将状态以异步的方式写入持久化存储









![](https://raw.githubusercontent.com/imattdu/img/main/img/202203191942590.png)







当 map 算子的状态备份和检查点分界线的位置备份被确认之后，该检查点操作 就可以被标记为完成







![](https://raw.githubusercontent.com/imattdu/img/main/img/202203191944177.png)



如果检查点操作失败，Flink 可以丢弃该检查点并继续正常执行，因为之后的某 一个检查点可能会成功





### Flink+Kafka 如何实现端到端的 exactly-once 语义



内部 —— 利用 checkpoint 机制，把状态存盘，发生故障的时候可以恢复， 保证内部的状态一致性

source —— kafka consumer 作为 source，可以将偏移量保存下来，如果后 续任务出现了故障，恢复的时候可以由连接器重置偏移量，重新消费数据， 保证一致性

sink —— kafka producer 作为 sink，采用两阶段提交 sink，需要实现一个 TwoPhaseCommitSinkFunction













![](https://raw.githubusercontent.com/imattdu/img/main/img/202203191947615.png)





当 checkpoint 启动时，JobManager 会将检查点分界线（barrier）注入数据流； barrier 会在算子间传递下去。





![](https://raw.githubusercontent.com/imattdu/img/main/img/202203191949720.png)





**每个算子会对当前的状态做个快照，保存到状态后端。对于 source 任务而言， 就会把当前的 offset 作为状态保存起来。下次从 checkpoint 恢复时，source 任务可 以重新提交偏移量，从上次保存的位置开始重新消费数据。**





![](https://raw.githubusercontent.com/imattdu/img/main/img/202203191950790.png)





sink 任务首先把数据写入外部 kafka，这些数据都属于预提交的事务（还不能 被消费）；当遇到 barrier 时，把状态保存到状态后端，并开启新的预提交事务。





当所有算子任务的快照完成，也就是这次的 checkpoint 完成时，JobManager 会 向所有任务发通知，确认这次 checkpoint 完成。 当 sink 任务收到确认通知，就会正式提交之前的事务，kafka 中未确认的数据 就改为“已确认”，数据就真正可以被消费了。





![](https://raw.githubusercontent.com/imattdu/img/main/img/202203191951125.png)











![](https://raw.githubusercontent.com/imattdu/img/main/img/202203191952133.png)

