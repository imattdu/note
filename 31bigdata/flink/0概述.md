





## 基本概念

### 是什么



Apache Flink 是一个框架和分布式处理引擎，用于对无界和有界数据流进行状态计算



### 特点



- 支持事件时间(event-time)和处理时间(processing-time) 语义
- 精确一次(exactly-once)的状态一致性保证
- 低延迟，每秒处理数百万个事件，毫秒级延迟
- 与众多常用存储系统的连接
- 高可用，动态扩展，实现7*24小时全天候运行



### **Flink** VS **Spark Streaming**



数据模型

-  spark 采用 RDD 模型，spark streaming 的 DStream 实际上也就是一组组小批

  数据 RDD 的集合

-  flink 基本数据模型是数据流，以及事件(Event)序列



运行时架构

-   spark 是批计算，将 DAG 划分为不同的 stage，一个完成后才可以计算下一个
-   flink 是标准的流执行模式，一个事件在一个节点处理完后可以直接发往下一个节点进行处理













迟到的数据放入侧边流



 8-9

数据产生8-9 处理的时候9:01









85763421



俩个通可以同时存在



[1,5] 1 2 4 3 5

[6,10] 6 7 8

t=3

8 来了关【1-5】的窗







wm传递：最小的值













在并行度不为1的时候：

下以上游分区woater mark最小值









状态保存在本地内存中， 检查点 taskmanager









```sh
state.backend: filesystem
```







![](https://raw.githubusercontent.com/imattdu/img/main/img/202202250048678.png)





检查点 a b 时间还没到检查点a, 正在处理1



1 2会被丢弃 





**黄1 蓝1**







1 2 3 4 保存1 5 6



// 前一次保存结束 到下一次保存开始

setMinPauseBetweenCheckpoints

可能检查点到了但是没超过这个数字 也不保存









端到端：输入源头 flink







幂等写入：最终一致性





5 10 15 5 10 15

5保存





预写日志(WAL):往外部系统写入并不能保证事务



